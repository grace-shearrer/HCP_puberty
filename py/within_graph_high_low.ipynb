{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib as mlp\n",
    "# mlp.use(\"Qt5Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import community\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alabaster==0.7.12\r\n",
      "anaconda-client==1.7.2\r\n",
      "anaconda-navigator==1.9.7\r\n",
      "anaconda-project==0.8.2\r\n",
      "appdirs==1.4.3\r\n",
      "appnope==0.1.0\r\n",
      "appscript==1.0.1\r\n",
      "asn1crypto==0.24.0\r\n",
      "astroid==2.1.0\r\n",
      "astropy==3.1\r\n",
      "atomicwrites==1.2.1\r\n",
      "attrs==18.2.0\r\n",
      "Babel==2.6.0\r\n",
      "backcall==0.1.0\r\n",
      "backports.os==0.1.1\r\n",
      "backports.shutil-get-terminal-size==1.0.0\r\n",
      "bctpy==0.5.0\r\n",
      "Beaker==1.10.1\r\n",
      "beautifulsoup4==4.6.3\r\n",
      "bitarray==0.8.3\r\n",
      "bkcharts==0.2\r\n",
      "blaze==0.11.3\r\n",
      "bleach==3.0.2\r\n",
      "bokeh==1.0.2\r\n",
      "boto==2.49.0\r\n",
      "Bottleneck==1.2.1\r\n",
      "bz2file==0.98\r\n",
      "certifi==2019.11.28\r\n",
      "cffi==1.12.3\r\n",
      "chardet==3.0.4\r\n",
      "Click==7.0\r\n",
      "cloudpickle==0.6.1\r\n",
      "clyent==1.2.2\r\n",
      "colorama==0.4.1\r\n",
      "community==1.0.0b1\r\n",
      "conda==4.8.2\r\n",
      "conda-build==3.17.6\r\n",
      "conda-package-handling==1.6.0\r\n",
      "conda-verify==3.1.1\r\n",
      "contextlib2==0.5.5\r\n",
      "cryptography==2.6.1\r\n",
      "cycler==0.10.0\r\n",
      "Cython==0.29.2\r\n",
      "cytoolz==0.9.0.1\r\n",
      "dask==1.0.0\r\n",
      "datalad==0.12.0rc6\r\n",
      "datashape==0.5.4\r\n",
      "decorator==4.3.0\r\n",
      "defusedxml==0.5.0\r\n",
      "Deprecated==1.2.6\r\n",
      "dill==0.2.9\r\n",
      "distributed==1.25.1\r\n",
      "docutils==0.14\r\n",
      "entrypoints==0.2.3\r\n",
      "et-xmlfile==1.0.1\r\n",
      "etelemetry==0.1.2\r\n",
      "fastcache==1.0.2\r\n",
      "fasteners==0.15\r\n",
      "filelock==3.0.10\r\n",
      "Flask==1.0.2\r\n",
      "Flask-Cors==3.0.7\r\n",
      "future==0.17.1\r\n",
      "gevent==1.3.7\r\n",
      "gitdb2==2.0.6\r\n",
      "GitPython==3.0.3\r\n",
      "glob2==0.6\r\n",
      "gmpy2==2.0.8\r\n",
      "graphviz==0.10.1\r\n",
      "greenlet==0.4.15\r\n",
      "h5py==2.8.0\r\n",
      "heapdict==1.0.0\r\n",
      "html5lib==1.0.1\r\n",
      "humanize==0.5.1\r\n",
      "idna==2.8\r\n",
      "imageio==2.4.1\r\n",
      "imagesize==1.1.0\r\n",
      "importlib-metadata==0.6\r\n",
      "ipykernel==5.1.0\r\n",
      "ipython==7.2.0\r\n",
      "ipython-genutils==0.2.0\r\n",
      "ipywidgets==7.4.2\r\n",
      "iso8601==0.1.12\r\n",
      "isort==4.3.4\r\n",
      "itsdangerous==1.1.0\r\n",
      "jdcal==1.4\r\n",
      "jedi==0.13.2\r\n",
      "Jinja2==2.10\r\n",
      "jsmin==2.2.2\r\n",
      "jsonschema==2.6.0\r\n",
      "jupyter==1.0.0\r\n",
      "jupyter-client==5.2.4\r\n",
      "jupyter-console==6.0.0\r\n",
      "jupyter-core==4.4.0\r\n",
      "jupyterlab==0.35.3\r\n",
      "jupyterlab-server==0.2.0\r\n",
      "keyring==17.0.0\r\n",
      "keyrings.alt==3.1.1\r\n",
      "kiwisolver==1.0.1\r\n",
      "lazy-object-proxy==1.3.1\r\n",
      "libarchive-c==2.8\r\n",
      "lief==0.9.0\r\n",
      "llvmlite==0.26.0\r\n",
      "locket==0.2.0\r\n",
      "lxml==4.2.5\r\n",
      "MarkupSafe==1.1.0\r\n",
      "matplotlib==3.0.3\r\n",
      "mccabe==0.6.1\r\n",
      "mistune==0.8.4\r\n",
      "mkl-fft==1.0.6\r\n",
      "mkl-random==1.0.2\r\n",
      "mock==3.0.5\r\n",
      "monotonic==1.5\r\n",
      "more-itertools==4.3.0\r\n",
      "mpmath==1.1.0\r\n",
      "msgpack==0.5.6\r\n",
      "multipledispatch==0.6.0\r\n",
      "multiprocess==0.70.7\r\n",
      "navigator-updater==0.2.1\r\n",
      "nbconvert==5.4.0\r\n",
      "nbformat==4.4.0\r\n",
      "networkx==2.2\r\n",
      "neurodocker==0.6.0\r\n",
      "nibabel==2.3.3\r\n",
      "nilearn==0.5.0\r\n",
      "nltk==3.4\r\n",
      "nose==1.3.7\r\n",
      "notebook==5.7.4\r\n",
      "numba==0.41.0\r\n",
      "numexpr==2.6.8\r\n",
      "numpy==1.15.4\r\n",
      "numpydoc==0.8.0\r\n",
      "objgraph==3.4.0\r\n",
      "odo==0.5.1\r\n",
      "olefile==0.46\r\n",
      "openpyxl==2.5.12\r\n",
      "packaging==18.0\r\n",
      "pandas==1.0.1\r\n",
      "pandocfilters==1.4.2\r\n",
      "parso==0.3.1\r\n",
      "partd==0.3.9\r\n",
      "path.py==11.5.0\r\n",
      "pathlib2==2.3.3\r\n",
      "patool==1.12\r\n",
      "patsy==0.5.1\r\n",
      "pep8==1.7.1\r\n",
      "pexpect==4.6.0\r\n",
      "pickleshare==0.7.5\r\n",
      "Pillow==5.3.0\r\n",
      "pkginfo==1.4.2\r\n",
      "pluggy==0.8.0\r\n",
      "ply==3.11\r\n",
      "prometheus-client==0.5.0\r\n",
      "prompt-toolkit==2.0.7\r\n",
      "psutil==5.4.8\r\n",
      "ptyprocess==0.6.0\r\n",
      "py==1.7.0\r\n",
      "pycodestyle==2.4.0\r\n",
      "pycosat==0.6.3\r\n",
      "pycparser==2.19\r\n",
      "pycrypto==2.6.1\r\n",
      "pycurl==7.43.0.2\r\n",
      "pyflakes==2.0.0\r\n",
      "PyGithub==1.43.8\r\n",
      "Pygments==2.3.1\r\n",
      "PyJWT==1.7.1\r\n",
      "pylint==2.2.2\r\n",
      "pyodbc==4.0.25\r\n",
      "PyOpenGL==3.1.0\r\n",
      "pyOpenSSL==19.0.0\r\n",
      "pyparsing==2.3.0\r\n",
      "PyQt5==5.12.1\r\n",
      "PyQt5-sip==4.19.15\r\n",
      "PySocks==1.6.8\r\n",
      "pytest==4.0.2\r\n",
      "pytest-arraydiff==0.3\r\n",
      "pytest-astropy==0.5.0\r\n",
      "pytest-doctestplus==0.2.0\r\n",
      "pytest-openfiles==0.3.1\r\n",
      "pytest-remotedata==0.3.1\r\n",
      "python-dateutil==2.7.5\r\n",
      "python-louvain==0.13\r\n",
      "pytz==2018.7\r\n",
      "PyWavelets==1.0.1\r\n",
      "PyYAML==3.13\r\n",
      "pyzmq==17.1.2\r\n",
      "QtAwesome==0.5.3\r\n",
      "qtconsole==4.4.3\r\n",
      "QtPy==1.5.2\r\n",
      "requests==2.21.0\r\n",
      "rope==0.11.0\r\n",
      "ruamel-yaml==0.15.46\r\n",
      "scikit-image==0.14.1\r\n",
      "scikit-learn==0.20.3\r\n",
      "scipy==1.1.0\r\n",
      "seaborn==0.9.0\r\n",
      "Send2Trash==1.5.0\r\n",
      "simplegeneric==0.8.1\r\n",
      "simplejson==3.16.0\r\n",
      "singledispatch==3.4.0.3\r\n",
      "six==1.12.0\r\n",
      "smmap2==2.0.5\r\n",
      "snowballstemmer==1.2.1\r\n",
      "sortedcollections==1.0.1\r\n",
      "sortedcontainers==2.1.0\r\n",
      "Sphinx==1.8.2\r\n",
      "sphinxcontrib-websupport==1.1.0\r\n",
      "spyder==3.3.2\r\n",
      "spyder-kernels==0.3.0\r\n",
      "SQLAlchemy==1.2.15\r\n",
      "statsmodels==0.9.0\r\n",
      "style==1.1.0\r\n",
      "sympy==1.3\r\n",
      "tables==3.4.4\r\n",
      "tblib==1.3.2\r\n",
      "terminado==0.8.1\r\n",
      "testpath==0.4.2\r\n",
      "toolz==0.9.0\r\n",
      "tornado==5.1.1\r\n",
      "tqdm==4.28.1\r\n",
      "traitlets==4.3.2\r\n",
      "unicodecsv==0.14.1\r\n",
      "update==0.0.1\r\n",
      "urllib3==1.24.2\r\n",
      "visbrain==0.4.4\r\n",
      "vispy==0.5.3\r\n",
      "wcwidth==0.1.7\r\n",
      "webencodings==0.5.1\r\n",
      "Werkzeug==0.14.1\r\n",
      "Whoosh==2.7.4\r\n",
      "widgetsnbextension==3.4.2\r\n",
      "wrapt==1.10.11\r\n",
      "wurlitzer==1.0.2\r\n",
      "xdot==1.0\r\n",
      "xlrd==1.2.0\r\n",
      "XlsxWriter==1.1.2\r\n",
      "xlwings==0.15.1\r\n",
      "xlwt==1.3.0\r\n",
      "zict==0.1.3\r\n"
     ]
    }
   ],
   "source": [
    "! pip freeze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to threshold graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(G, corr_direction):\n",
    "    ##Creates a copy of the graph\n",
    "    H = G.copy()\n",
    "    for stock1, stock2, weight in list(G.edges(data=True)):\n",
    "        if corr_direction == \"positive\":\n",
    "            if weight[\"weight\"] <0:\n",
    "                H.remove_edge(stock1, stock2)\n",
    "        else:\n",
    "            if weight[\"weight\"] >=0:\n",
    "                H.remove_edge(stock1, stock2)\n",
    "    return(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to unpickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onetoughjar(path2dic):\n",
    "    with open(path2dic, 'rb') as pickle_file:\n",
    "        try:\n",
    "            while True:\n",
    "                output = pickle.load(pickle_file)\n",
    "        except EOFError:\n",
    "            pass\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create graphs of all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grace_graph(graph, group):\n",
    "    G=graph\n",
    "    positions = nx.circular_layout(G)\n",
    "    size = 100\n",
    "    title= \"Modularity and edge weights \\n of average %s graph\"%(group)\n",
    "    save=\"%s_graph.png\"%(group)\n",
    "    \n",
    "    edges,weights = zip(*nx.get_edge_attributes(G, 'weight').items())\n",
    "\n",
    "    nodes, color = zip(*nx.get_node_attributes(G, 'modules').items()) #if your modules are named different change here\n",
    "    # nodes, names = zip(*nx.get_node_attributes(graph, 'label').items()) #if your modules are named different change here\n",
    "    \n",
    "    #Figure size\n",
    "    plt.figure(figsize=(80,50))\n",
    "\n",
    "    #draws nodes\n",
    "    color = np.array(color)\n",
    "    n_color=len(list(set(color)))\n",
    "    # nColormap=plt.cm.Set3 #check here if you want different colors https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "    cM=color.max()\n",
    "    cm=color.min()\n",
    "    # get discrete colormap\n",
    "    nColormap = plt.get_cmap('Set3', n_color)\n",
    "\n",
    "    # scaling\n",
    "    sz=np.array(size)\n",
    "    scale=15000/sz.max()\n",
    "    sza=sz*scale\n",
    "    # print(sz.shape)\n",
    "\n",
    "    y=nx.draw_networkx_nodes(G,positions,\n",
    "                           node_color=color,\n",
    "                           node_size=sza,\n",
    "                           alpha=0.8,\n",
    "                           cmap= nColormap,\n",
    "                           vmin=cm ,vmax=cM)\n",
    "\n",
    "    #Styling for labels\n",
    "    nx.draw_networkx_labels(G, positions,\n",
    "                            # labels = label_dict,\n",
    "                            font_size=50,\n",
    "                            font_family='sans-serif',\n",
    "                            fontweight = 'bold')\n",
    "\n",
    "    #draw edges\n",
    "    weights=np.array(weights)\n",
    "    eColormap=plt.cm.gist_rainbow #check here if you want different colors https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "    # scaling\n",
    "    wt=list(set(weights))\n",
    "    wt=np.array(wt)\n",
    "    wt2=-np.sort(-wt)\n",
    "    wt0=wt2[1]\n",
    "\n",
    "    escale=1/wt0\n",
    "    esza=weights*escale\n",
    "    E=list(set(esza))\n",
    "    E2=-np.sort(-np.array(E))\n",
    "    M=1\n",
    "    m=0\n",
    "\n",
    "    x=nx.draw_networkx_edges(G, positions,\n",
    "                           edge_list=edges,\n",
    "                           style='solid',\n",
    "                           width = np.square(esza)*20,\n",
    "                           edge_color = esza,\n",
    "                           edge_cmap=eColormap,\n",
    "                           edge_vmin=m,\n",
    "                           edge_vmax=M)\n",
    "\n",
    "    #COLORBAR STUFF\n",
    "    node_bar=plt.colorbar(y, label='Module value')\n",
    "\n",
    "    tick_locs = (np.arange(n_color) + 0.5)*(n_color-1)/n_color\n",
    "    node_bar.set_ticks(tick_locs)\n",
    "\n",
    "    # set tick labels (as before)\n",
    "    node_bar.set_ticklabels(np.arange(n_color))\n",
    "\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=eColormap, norm=plt.Normalize(vmin = m, vmax=M))\n",
    "    sm._A = []\n",
    "    edge_bar=plt.colorbar(sm)\n",
    "\n",
    "    for l in edge_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "    for l in node_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "        l.set_verticalalignment('center')\n",
    "\n",
    "    node_bar.set_label('Modularity',fontsize = 50)\n",
    "    edge_bar.set_label('Strength of edge weight',fontsize = 50)\n",
    "    # Final plot stuff\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.title(title, fontsize = 100)\n",
    "    basepath='/Users/gracer/Google Drive/HCP_graph/1200/images'\n",
    "\n",
    "    plt.savefig(os.path.join(basepath,save), format=\"PNG\")\n",
    "    plt.show()\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_fig(G, group, IC):\n",
    "    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "    #nodes, size = zip(*nx.get_node_attributes(G,'clustering').items())\n",
    "\n",
    "    positions=nx.circular_layout(G)\n",
    "    plt.figure(figsize=(80,50))\n",
    "    ### NODES ####\n",
    "    color = np.array(list(G.nodes))\n",
    "    color = np.array(color)\n",
    "    n_color=len(list(set(color)))\n",
    "    nColormap = plt.get_cmap('Set3', n_color)\n",
    "\n",
    "    y=nx.draw_networkx_nodes(G,positions,\n",
    "                           node_color=color,\n",
    "                           node_size=15000,\n",
    "                           alpha=1.0,\n",
    "                           cmap= nColormap,\n",
    "                           vmin=0,vmax=n_color )\n",
    "\n",
    "    #Styling for labels\n",
    "    nx.draw_networkx_labels(G, positions, font_size=100,\n",
    "                            font_family='sans-serif', fontweight = 'bold')\n",
    "    \n",
    "    ### EDGES ####\n",
    "    weights=np.array(weights)\n",
    "\n",
    "    m=weights.min()\n",
    "    M=weights.max()\n",
    "    \n",
    "    eColormap=plt.cm.gist_rainbow\n",
    "    \n",
    "    x=nx.draw_networkx_edges(G, positions, \n",
    "                             edge_list=edges,\n",
    "                             style='solid', \n",
    "                             width = weights,\n",
    "                             edge_color = weights, \n",
    "                             edge_vmin=m, \n",
    "                             edge_vmax=M, \n",
    "                             edge_cmap= eColormap)\n",
    "\n",
    "    \n",
    "    node_bar=plt.colorbar(y, label='Module value')\n",
    "    \n",
    "    tick_locs = (np.arange(n_color) + 0.5)*(n_color-1)/n_color\n",
    "    node_bar.set_ticks(tick_locs)\n",
    "\n",
    "    # set tick labels (as before)\n",
    "    node_bar.set_ticklabels(np.arange(n_color))\n",
    "\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=eColormap, norm=plt.Normalize(vmin = m, vmax=M))\n",
    "    sm._A = []\n",
    "    edge_bar=plt.colorbar(sm)\n",
    "\n",
    "    for l in edge_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "    for l in node_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "        l.set_verticalalignment('center')\n",
    "\n",
    "    node_bar.set_label('Modularity',fontsize = 50)\n",
    "    edge_bar.set_label('Strength of edge weight',fontsize = 50)\n",
    "    \n",
    "    plt.title(\"Module Connectivity Weights %s %s\"%(group, IC), fontsize = 100)\n",
    "    plt.axis('off')\n",
    "    basepath='/Users/gracer/Google Drive/HCP_graph/1200/images'\n",
    "#     plt.savefig(os.path.join(basepath,\"modularity_%s.png\"%(Type)), format=\"PNG\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def com_create(mu):\n",
    "    partition = community.best_partition(mu)\n",
    "    vals = list(partition.values())\n",
    "    nx.set_node_attributes(mu, partition, 'modules')\n",
    "    return((partition,vals, mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_pvalues(df):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            pvalues[r][c] = round(pearsonr(df[r], df[c])[1], 4)\n",
    "    return pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to visualize the module graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inmod_graph(graph, group):\n",
    "#     graph=threshold(graph,dirp,minp)\n",
    "    e,w = zip(*nx.get_edge_attributes(graph, 'weight').items())\n",
    "    positions = nx.circular_layout(graph)\n",
    "    size = 100\n",
    "    title= \"Modularity and edge weights \\n of average %s graph\"%(group)\n",
    "    save=\"%s_graph.png\"%(group)\n",
    "    \n",
    "    edges,weights = zip(*nx.get_edge_attributes(graph, 'weight').items())\n",
    "\n",
    "    nodes, color = zip(*nx.get_node_attributes(graph, 'modules').items()) #if your modules are named different change here\n",
    "    # nodes, names = zip(*nx.get_node_attributes(graph, 'label').items()) #if your modules are named different change here\n",
    "    g=graph\n",
    "    #Figure size\n",
    "    plt.figure(figsize=(80,50))\n",
    "\n",
    "    #draws nodes\n",
    "    color = np.array(color)\n",
    "    n_color=len(list(set(color)))\n",
    "    # nColormap=plt.cm.Set3 #check here if you want different colors https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "    cM=color.max()\n",
    "    cm=color.min()\n",
    "    # get discrete colormap\n",
    "    nColormap = plt.get_cmap('Set3', n_color)\n",
    "\n",
    "    # scaling\n",
    "    sz=np.array(size)\n",
    "    scale=15000/sz.max()\n",
    "    sza=sz*scale\n",
    "    # print(sz.shape)\n",
    "\n",
    "    y=nx.draw_networkx_nodes(g,positions,\n",
    "                           node_color=color,\n",
    "                           node_size=sza,\n",
    "                           alpha=0.8,\n",
    "                           cmap= nColormap,\n",
    "                           vmin=cm ,vmax=cM)\n",
    "\n",
    "    #Styling for labels\n",
    "    nx.draw_networkx_labels(g, positions,\n",
    "                            # labels = label_dict,\n",
    "                            font_size=50,\n",
    "                            font_family='sans-serif',\n",
    "                            fontweight = 'bold')\n",
    "\n",
    "    #draw edges\n",
    "    weights=np.array(weights)\n",
    "    eColormap=plt.cm.gist_rainbow #check here if you want different colors https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "#     # scaling\n",
    "#     wt=list(set(weights))\n",
    "#     wt=np.array(wt)\n",
    "#     wt2=-np.sort(-wt)\n",
    "#     wt0=wt2[1]\n",
    "\n",
    "#     escale=1/wt0\n",
    "#     esza=weights*escale\n",
    "#     E=list(set(esza))\n",
    "#     E2=-np.sort(-np.array(E))\n",
    "    M=1\n",
    "    m=-1\n",
    "\n",
    "    x=nx.draw_networkx_edges(g, positions,\n",
    "                           edge_list=edges,\n",
    "                           style='solid',\n",
    "                           width = np.square(weights)*100,\n",
    "                           edge_color = weights,\n",
    "                           edge_cmap=eColormap,\n",
    "                           edge_vmin=m,\n",
    "                           edge_vmax=M)\n",
    "\n",
    "    #COLORBAR STUFF\n",
    "    node_bar=plt.colorbar(y, label='Module value')\n",
    "\n",
    "    tick_locs = (np.arange(n_color) + 0.5)*(n_color-1)/n_color\n",
    "    node_bar.set_ticks(tick_locs)\n",
    "\n",
    "    # set tick labels (as before)\n",
    "    node_bar.set_ticklabels(np.arange(n_color))\n",
    "\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=eColormap, norm=plt.Normalize(vmin = m, vmax=M))\n",
    "    sm._A = []\n",
    "    edge_bar=plt.colorbar(sm)\n",
    "\n",
    "    for l in edge_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "    for l in node_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "        l.set_verticalalignment('center')\n",
    "\n",
    "    node_bar.set_label('Modularity',fontsize = 50)\n",
    "    edge_bar.set_label('Strength of edge weight',fontsize = 50)\n",
    "    # Final plot stuff\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.title(title, fontsize = 100)\n",
    "    basepath='/Users/gracer/Google Drive/HCP_graph/1200/images'\n",
    "\n",
    "    plt.savefig(os.path.join(basepath,save), format=\"PNG\")\n",
    "    plt.show()\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to look at the p values quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skimP(mat):\n",
    "    mask = np.zeros_like(mat)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    with sns.axes_style(\"white\"):\n",
    "        f, ax = plt.subplots(figsize=(14, 10))\n",
    "        ax = sns.heatmap(mat, mask=mask,annot=True, center=0.05,square=True, cmap='gist_ncar')\n",
    "#         ax.set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate graph and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_make_graphs(key, values, direction):\n",
    "    ########################################\n",
    "    cor_matrix = np.asmatrix(values)\n",
    "    G = nx.from_numpy_matrix(cor_matrix)\n",
    "    ########################################\n",
    "    tG = threshold(G, direction)\n",
    "    if len(list(tG.edges(data=True))) > 0:\n",
    "        if direction == 'negative':\n",
    "            print('start negative')\n",
    "            edges,weights = zip(*nx.get_edge_attributes(tG,'weight').items())\n",
    "            wts=tuple(abs(np.array(weights)))\n",
    "            total=[]\n",
    "            for x in enumerate(edges):\n",
    "                y={'weight':wts[x[0]]}\n",
    "                total.append(x[1]+(y,))\n",
    "            tG.add_edges_from(total)\n",
    "\n",
    "        ########################################\n",
    "        (partition,vals,graph)=com_create(tG)\n",
    "        nx.set_node_attributes(tG, partition, 'modules')\n",
    "        ########################################\n",
    "        x=abs(cor_matrix)\n",
    "        mu=x.mean()\n",
    "        ########################################\n",
    "        clustering = nx.clustering(tG, weight=True)\n",
    "        ########################################\n",
    "        centrality = nx.betweenness_centrality(tG, weight=True)\n",
    "        ########################################\n",
    "        nx.set_node_attributes(tG, centrality, 'centrality')\n",
    "        nx.set_node_attributes(tG, clustering, 'clustering')\n",
    "        nx.set_node_attributes(tG, partition, 'modules')\n",
    "\n",
    "        stocks = values.index.values\n",
    "        tG = nx.relabel_nodes(tG,lambda x: stocks[x])\n",
    "        ########################################\n",
    "        return({'mean_FC':mu, 'graphs':tG, 'clustering_coeff':clustering, 'btn_centrality':centrality,  'modules':{'partition':partition,\n",
    "    'values':vals,'graph':graph}})\n",
    "    else:\n",
    "        print('this is empty')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base dictionary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dict={'late':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           },'early':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           }\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in appropriate files\n",
    "1. Header = These are the ICs from the 15 dimenstion\n",
    "2. labels = These are labels from the glasser and gordon merged brains (allowing for cortex and subcortex)\n",
    "3. covars = These are the values of BMI, age at onset of menses, race, age, and head motion. The same file was used in FSLNETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['IC1','IC2','IC3','IC4','IC5','IC6','IC7','IC8','IC9','IC10','IC11','IC12','IC13','IC14','IC15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/Users/gracer/Google Drive/HCP_graph/1200/brains/lables_glasser.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars=pd.read_csv('/Users/gracer/Google Drive/HCP_graph/1200/datasets/subs510.csv', sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars.columns=['idx','subject','group','BMI','AoM','int','race','age','motion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "covars.drop_duplicates(subset='subject', keep=\"last\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars['subject']=covars['subject'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_low=pd.read_csv('/Users/gracer/Google Drive/HCP_graph/1200/datasets/post_hoc.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl=high_low[['Subject','AoM']]\n",
    "hl=hl.dropna()\n",
    "hl.columns = [\"subject\", \"high_low\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in all timeseries data from each participant into data_dict. \n",
    "These are the netmat2 files. They are zscores per TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_dict={'late':hl.loc[hl['high_low']=='late'],'early': hl.loc[hl['high_low'] == 'early']}\n",
    "data_dict={'late':{},'early':{}}\n",
    "for key, df in raw_dict.items():\n",
    "    print(key)\n",
    "    for sub in df['subject']:\n",
    "        path=os.path.join(\n",
    "            '/Users/gracer/Downloads/HCP_S1200_PTNmaps_d15_25_50_100/3T_HCP1200_MSMAll_d15_ts2_Z/puberty/%i.txt'%sub)\n",
    "        data_dict[key][sub]=pd.read_csv(path,sep='\\t',names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data_dict['early'].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that you have 212 subjects/files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset the ICs of interest\n",
    "Don't need all the ICs. Just the ones already associated with BMI and puberty. This allows us to look at the relationships within IC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interest={'late':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           },'early':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           }\n",
    "          }\n",
    "for t, dt in interest.items():\n",
    "    print(t)\n",
    "    for x,y in dt.items():\n",
    "        print(x)\n",
    "        for k,v in y.items():\n",
    "            print(k)\n",
    "            for key, value in data_dict[t].items():\n",
    "                v[key]=value[k]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datatables with the rows as subjects and columns as parcels per IC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on we will seperate all ICs from each other. This allows us to look at the parcellation per IC. The dfs is a dictionary of all ICs of interest. The columns are the parcels and rows are the subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs = {'late':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           },'early':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           }\n",
    "          }\n",
    "for t, df in interest.items():\n",
    "    for group, value in df.items():\n",
    "        for IC,v in value.items():\n",
    "            x=pd.DataFrame.from_dict(v, orient='index')\n",
    "            print(x.shape)\n",
    "            x['subject']=x.index\n",
    "            x['subject'] = x['subject'].astype('int64')\n",
    "            hl['subject']= hl['subject'].astype('int64')\n",
    "            y=pd.merge(x, covars, left_on='subject', right_on='subject')\n",
    "            print(y.shape)\n",
    "            z=pd.merge(y, hl, left_on='subject', right_on='subject')\n",
    "            print(z.shape)\n",
    "            del z['group']\n",
    "            del z['idx']\n",
    "            z.set_index('subject', inplace=True)\n",
    "            dfs[t][group][IC]=z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['late']['BMI']['IC1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t, item in dfs.items():\n",
    "    for group, value in item.items():\n",
    "        for IC, v in value.items():\n",
    "            del v['idx']\n",
    "            dfs[t][group][IC]=v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding the zscores \n",
    "Only keeping zscores > 3.5 and greater than 75 of the participants must have a value for the score to keep the column. This is to threshold out noise and missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zscores_thr= {'late':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           },'early':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           }\n",
    "          }\n",
    "\n",
    "for t, df in dfs.items():\n",
    "    for group, value in df.items():\n",
    "        print(group)\n",
    "        for IC,v in value.items():\n",
    "            print(IC)\n",
    "            x = v[(v.iloc[:,1:379]>3.5) | (v.iloc[:,1:379]<-3.5)]\n",
    "            y=x.dropna(axis=1, how='all')\n",
    "            test=y.isna().mean()\n",
    "            q = y.loc[:, y.isna().mean() < .25]\n",
    "            z=pd.concat([v.iloc[:,379:], q], axis=1)\n",
    "            zscores_thr[t][group][IC]=z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zscores_thr['early']['BMI']['IC1'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the graphs with positive values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important\n",
    "### Correlations\n",
    "This is probably the most important part. Here we are taking our (subxparcel) dataframes we thresholded above and we are generating a correlation matrix using a Pearson's Product correlation (R). Within each matrix, there will be positive and negative correlation values. This can be a problem with the graph metrics we want to use.\n",
    "### Graphs\n",
    "To avoid the issue of negative and positive values, we are going to threshold each correlation matrix twice. \n",
    "1. Positive correlations\n",
    "2. Negative correltions\n",
    "\n",
    "We will then use the absolute value of the negative correlations to mimic a positive correlation. We will keep these seperate for the rest of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graphs = {'late':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           },'early':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}}}\n",
    "\n",
    "for t, item in zscores_thr.items():\n",
    "    for group, value in item.items():\n",
    "#         print(key)\n",
    "        for IC, v in value.items():\n",
    "            print(group)\n",
    "            graphs[t][group][IC]=mu_make_graphs(IC, v.corr(), 'positive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating graphs with negative values\n",
    "Unable to get communities with negative values need to keep seperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nega_graphs = {'late':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           },'early':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}}}\n",
    "\n",
    "for t, item in zscores_thr.items():\n",
    "    for group, value in item.items():\n",
    "        print(group)\n",
    "        for IC, v in value.items():\n",
    "            print(IC)\n",
    "            nega_graphs[t][group][IC]=mu_make_graphs(IC, v.corr(), 'negative')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the total graphs for all ICs in the interaction group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These graphs will show all the nodes in each IC (positive and negative). It will also show what community each node belongs to. Community struture will be a measure of density. Denser connections will form modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, value in graphs['late']['int'].items():\n",
    "    grace_graph(value['graphs'], 'Int_%s'%key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, value in nega_graphs['late']['int'].items():\n",
    "    grace_graph(value['graphs'], 'Int_%s'%key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## writing all the adjacency matrices and topologocial values to csv to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for key, value in graphs.items():\n",
    "#     print(key)\n",
    "#     for k, v in value.items():\n",
    "#         print(k)\n",
    "#         cc=pd.DataFrame.from_dict(v['clustering_coeff'], orient='index')\n",
    "#         btw=pd.DataFrame.from_dict(v['btn_centrality'], orient='index')\n",
    "#         mod=pd.DataFrame.from_dict(v['modules']['partition'], orient='index')\n",
    "#         test3 = pd.concat([cc, btw, mod], axis=1)\n",
    "#         test3.columns = ['cc','btw','mod']\n",
    "#         print(test3.shape)\n",
    "#         test3.set_index([list(zscores_thr[key][k].columns.values)], inplace=True)\n",
    "#         adj=nx.to_pandas_adjacency(v['graphs'])\n",
    "#         print(adj.shape)\n",
    "#         df=adj.merge(test3, left_index=True, right_index=True)\n",
    "#         pd.DataFrame.to_csv(df, '/Users/gracer/Google Drive/HCP_graph/1200/datasets/%s_%s_thresh.csv'%(key,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for key, value in nega_graphs.items():\n",
    "#     print(key)\n",
    "#     for k, v in value.items():\n",
    "#         print(k)\n",
    "#         cc=pd.DataFrame.from_dict(v['clustering_coeff'], orient='index')\n",
    "#         btw=pd.DataFrame.from_dict(v['btn_centrality'], orient='index')\n",
    "#         test3 = pd.concat([cc, btw], axis=1)\n",
    "#         test3.columns = ['cc','btw']\n",
    "#         test3.set_index([list(zscores_thr[key][k].columns.values)], inplace=True)\n",
    "#         pd.DataFrame.to_csv(test3, '/Users/gracer/Google Drive/HCP_graph/1200/datasets/%s_%s_thresh_neg.csv'%(key,k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the within module graph \n",
    "These are graphs that look at the connectivity within each module. This shows us how the most related areas (densely connected) interact with each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subgraphs = {'late':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           },'early':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}}}\n",
    "\n",
    "for t, item in graphs.items():\n",
    "    for group, v in item.items():\n",
    "        for IC, value in v.items():\n",
    "            print(IC)\n",
    "            G=value['graphs']\n",
    "            mod=G.nodes(data=True)[group]['modules']\n",
    "            print(mod)\n",
    "            interest=[k for k,v in nx.get_node_attributes(G, 'modules').items() if v == mod]\n",
    "            print(interest)\n",
    "            X=nx.subgraph(G, interest)\n",
    "            subgraphs[t][group][IC]=X\n",
    "#             inmod_graph(X, 'interaction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Overall, within each module the interaction term is segregated. These are positive graphs, therefore they are either increasing or decreasing together. This indicates to me that the interaction is fairly unique and not densely correlated. It maybe that is it correlated more strongly to other modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nega_subgraphs = {'late':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           },'early':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}}}\n",
    "\n",
    "for t, item in nega_graphs.items():\n",
    "    for group, v in item.items():\n",
    "        for IC, value in v.items():\n",
    "            print(IC)\n",
    "            G=value['graphs']\n",
    "            mod=G.nodes(data=True)[group]['modules']\n",
    "            print(mod)\n",
    "            interest=[k for k,v in nx.get_node_attributes(G, 'modules').items() if v == mod]\n",
    "            print(interest)\n",
    "            X=nx.subgraph(G, interest)\n",
    "            nega_subgraphs[t][group][IC]=X\n",
    "#             inmod_graph(X, 'interaction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "we can see that the inverse correlations are overall much weaker than the positive. Further, the interaction term is positively correlated with BMI and head motion, but negatively correlated with age at onset of menses. This is expected since the relationship between BMI and age at onset of menses is inverse. (see R notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating module based graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "community_graphs= {'late':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           },'early':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}}}\n",
    "for t, item in graphs.items():\n",
    "    for group, v in item.items():\n",
    "        for IC, data in v.items():\n",
    "            comm_graph = community.induced_graph(data['modules']['partition'], \n",
    "                                            data['modules']['graph'])\n",
    "            community_graphs[t][group][IC]=comm_graph\n",
    "            print(IC)\n",
    "#             module_fig(comm_graph, group, IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "The module graphs show that the connectivity of the modules containing the interaction term are rather weak. Especially in IC3 and IC12 (module 2), they are only weakly related to the other modules. In ICs 4 and 13 we see a more robust response. This suggest to me that 4 and 12 are driving their respective connections with 3 and 12. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nega_community_graphs= {'late':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           },'early':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}}}\n",
    "\n",
    "for t, item in nega_graphs.items():\n",
    "    for group, v in item.items():\n",
    "        for IC, data in v.items():\n",
    "            comm_graph = community.induced_graph(data['modules']['partition'], \n",
    "                                            data['modules']['graph'])\n",
    "            nega_community_graphs[t][group][IC]=comm_graph\n",
    "            print(IC)\n",
    "#             module_fig(comm_graph, group, IC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_graphs['late']['int']['IC6'].nodes(data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "There are far fewer nodes and modules in the negative correlation graphs. Interestingly, in the IC2 and IC3 the module with the interaction term is different (0 vs. 2). It appears IC2 is driving the inverse relationship. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_fig(community_graphs['late']['int']['IC6'], 'int', 'IC6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_fig(community_graphs['early']['int']['IC6'], 'int', 'IC6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs['late']['int']['IC6'].nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G=graphs['late']['int']['IC6']['graphs']\n",
    "n2,btw = zip(*nx.get_node_attributes(G, 'centrality').items())\n",
    "e,w = zip(*nx.get_edge_attributes(G, 'weight').items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pd.DataFrame(list(btw)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "exports= {'late':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}\n",
    "           },'early':\n",
    "           {'BMI':\n",
    "            {'IC1':{},'IC3':{},'IC4':{},'IC5':{},'IC6':{},'IC7':{},'IC8':{},'IC9':{},'IC10':{},'IC11':{},'IC12':{},'IC13':{},'IC14':{},'IC15':{}},\n",
    "            'AoM':\n",
    "            {'IC12':{},'IC15':{}},\n",
    "            'int':\n",
    "            {'IC2':{},'IC3':{},'IC6':{},'IC12':{},'IC13':{}}}}\n",
    "\n",
    "nodelist=[]\n",
    "edgelist=[]\n",
    "for t, item in graphs.items():\n",
    "    for group, value in item.items():\n",
    "        for IC, v in value.items():\n",
    "            e,w = zip(*nx.get_edge_attributes(v['graphs'], 'weight').items())\n",
    "            edf = pd.DataFrame(list(e),columns=['x','y'])\n",
    "            edf['edge_weight']=list(w)\n",
    "            edf['group']=group\n",
    "            edf['early_late']=t\n",
    "            edf['IC']=IC\n",
    "            n1,cc = zip(*nx.get_node_attributes(v['graphs'], 'clustering').items())\n",
    "            df=pd.DataFrame(list(cc),columns=['cc'])\n",
    "            n2,btw = zip(*nx.get_node_attributes(v['graphs'], 'centrality').items())\n",
    "            df['btw']=list(btw)\n",
    "            n3,mod = zip(*nx.get_node_attributes(v['graphs'], 'modules').items())\n",
    "            df['module']=list(mod)\n",
    "            df['group']=group\n",
    "            df['early_late']=t\n",
    "            df['IC']=IC\n",
    "            df['node']=n2\n",
    "            exports[t][group][IC]=df\n",
    "            nodelist.append(df)\n",
    "            edgelist.append(edf)\n",
    "        \n",
    "            \n",
    "\n",
    "node_df=pd.concat(nodelist)\n",
    "pd.DataFrame.to_csv(node_df,'/Users/gracer/Google Drive/HCP_graph/1200/datasets/early_late_nodes.csv',sep=',')\n",
    "edge_df=pd.concat(edgelist)\n",
    "edge_df = edge_df[edge_df['x'] != edge_df['y']]\n",
    "pd.DataFrame.to_csv(edge_df,'/Users/gracer/Google Drive/HCP_graph/1200/datasets/early_late_edges.csv',sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exports['late']['BMI']['IC1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmod_graph(X, 'interaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA={'interest':interest,\n",
    "'dfs':dfs,\n",
    "'zscores_thr':zscores_thr,\n",
    "'graphs':graphs,\n",
    "'nega_graphs':nega_graphs,\n",
    "'subgraphs':subgraphs,\n",
    "'community_graphs':community_graphs,\n",
    "'exports':exports\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA['community_graphs']['late']['BMI']['IC1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(ALL_DATA, open('/Users/gracer/Google Drive/HCP_graph/1200/datasets/finalel.pkl', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA=onetoughjar('/Users/gracer/Google Drive/HCP_graph/1200/datasets/finalel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=ALL_DATA['dfs']\n",
    "graphs=ALL_DATA['graphs']\n",
    "zscores_thr=ALL_DATA['zscores_thr']\n",
    "nega_graphs=ALL_DATA['nega_graphs']\n",
    "dfs=ALL_DATA['dfs']\n",
    "subgraphs=ALL_DATA['subgraphs']\n",
    "community_graphs=ALL_DATA['community_graphs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeDataView({'BMI': {'modules': 0, 'centrality': 0.006129362314031303, 'clustering': 0.5833333333333334}, 'AoM': {'modules': 1, 'centrality': 0.00714285714285714, 'clustering': 0.8526315789473684}, 'int': {'modules': 0, 'centrality': 0.009368950832365466, 'clustering': 0.5333333333333333}, 'race': {'modules': 0, 'centrality': 0.03450670811756453, 'clustering': 0.5441176470588235}, 'age': {'modules': 0, 'centrality': 0.01929470975382023, 'clustering': 0.48484848484848486}, 'motion': {'modules': 0, 'centrality': 0.001531994911785852, 'clustering': 0.7619047619047619}, 43: {'modules': 2, 'centrality': 0.011020831096666312, 'clustering': 0.9428571428571428}, 56: {'modules': 3, 'centrality': 0.0011506756460964074, 'clustering': 0.9680672268907563}, 60: {'modules': 4, 'centrality': 6.734401077504172e-05, 'clustering': 0.9964349376114082}, 63: {'modules': 4, 'centrality': 0.0011506756460964074, 'clustering': 0.9680672268907563}, 96: {'modules': 2, 'centrality': 0.00846566268783936, 'clustering': 0.9445378151260504}, 100: {'modules': 5, 'centrality': 0.004055533080570564, 'clustering': 0.9317460317460318}, 102: {'modules': 5, 'centrality': 0.004055533080570564, 'clustering': 0.9317460317460318}, 117: {'modules': 3, 'centrality': 0.006453203161167474, 'clustering': 0.9238095238095239}, 123: {'modules': 2, 'centrality': 0.004055533080570564, 'clustering': 0.9317460317460318}, 132: {'modules': 3, 'centrality': 0.006453203161167474, 'clustering': 0.9238095238095239}, 155: {'modules': 2, 'centrality': 6.734401077504172e-05, 'clustering': 0.9964349376114082}, 158: {'modules': 6, 'centrality': 6.734401077504172e-05, 'clustering': 0.9964349376114082}, 161: {'modules': 6, 'centrality': 0.0050795114793885056, 'clustering': 0.9495798319327731}, 163: {'modules': 0, 'centrality': 0.007837247008345483, 'clustering': 0.5}, 165: {'modules': 2, 'centrality': 0.0011506756460964074, 'clustering': 0.9680672268907563}, 166: {'modules': 2, 'centrality': 0.0011506756460964074, 'clustering': 0.9680672268907563}, 185: {'modules': 3, 'centrality': 0.04655537011552592, 'clustering': 0.8513513513513513}, 224: {'modules': 0, 'centrality': 0.00019357336430507162, 'clustering': 0.9333333333333333}, 236: {'modules': 3, 'centrality': 0.013304996795466149, 'clustering': 0.9411764705882353}, 243: {'modules': 4, 'centrality': 0.0011506756460964074, 'clustering': 0.9680672268907563}, 275: {'modules': 7, 'centrality': 0.008027638254119089, 'clustering': 0.9109243697478991}, 276: {'modules': 8, 'centrality': 0.00846566268783936, 'clustering': 0.9445378151260504}, 280: {'modules': 5, 'centrality': 0.004055533080570564, 'clustering': 0.9317460317460318}, 282: {'modules': 5, 'centrality': 6.734401077504172e-05, 'clustering': 0.9964349376114082}, 297: {'modules': 3, 'centrality': 0.02657930238134334, 'clustering': 0.8392603129445235}, 303: {'modules': 5, 'centrality': 0.004055533080570564, 'clustering': 0.9317460317460318}, 311: {'modules': 3, 'centrality': 0.0040223490752611234, 'clustering': 0.9294117647058824}, 312: {'modules': 3, 'centrality': 0.004055533080570564, 'clustering': 0.9317460317460318}, 314: {'modules': 8, 'centrality': 0.0050795114793885056, 'clustering': 0.9495798319327731}, 335: {'modules': 8, 'centrality': 0.0011506756460964074, 'clustering': 0.9680672268907563}, 338: {'modules': 6, 'centrality': 6.734401077504172e-05, 'clustering': 0.9964349376114082}, 339: {'modules': 6, 'centrality': 0.005045351473922904, 'clustering': 0.948306595365419}, 341: {'modules': 8, 'centrality': 0.0029722014452491993, 'clustering': 0.9563025210084034}, 345: {'modules': 8, 'centrality': 0.0011506756460964074, 'clustering': 0.9680672268907563}, 346: {'modules': 5, 'centrality': 0.0029722014452491993, 'clustering': 0.9563025210084034}, 365: {'modules': 3, 'centrality': 6.734401077504172e-05, 'clustering': 0.9964349376114082}, 369: {'modules': 5, 'centrality': 0.01687285513134209, 'clustering': 0.8825396825396825}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs['late']['int']['IC6']['graphs'].nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
